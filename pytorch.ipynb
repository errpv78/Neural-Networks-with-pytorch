{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6238, -1.2271, -0.1789, -1.3841,  0.8407]])\n",
      "tensor([[0.7961, 0.9875, 0.1213, 0.3976, 0.8711]])\n",
      "tensor([[-0.4036]])\n",
      "tensor([[-1.5481]])\n",
      "tensor([[0.1244]])\n",
      "tensor([[0.1244]])\n",
      "\n",
      "\n",
      " tensor([[-0.6238, -1.2271, -0.1789, -1.3841,  0.8407]])\n",
      "tensor([[-0.6238],\n",
      "        [-1.2271],\n",
      "        [-0.1789],\n",
      "        [-1.3841],\n",
      "        [ 0.8407]])\n",
      "tensor([[-0.6238, -1.2271, -0.1789, -1.3841,  0.8407]])\n",
      "tensor([[-0.6238],\n",
      "        [-1.2271],\n",
      "        [-0.1789],\n",
      "        [-1.3841],\n",
      "        [ 0.8407]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Basic neural network\"\"\"\n",
    "import torch\n",
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "torch.manual_seed(78)\n",
    "features = torch.randn((1,5)) # matrix of 1*5, these are features\n",
    "weights = torch.rand_like(features) # to create a random matrix with\n",
    "# same dimensions as features\n",
    "\n",
    "bias = torch.randn((1,1))\n",
    "print(features)\n",
    "print(weights)\n",
    "print(bias)\n",
    "# print(features.t())\n",
    "print(torch.matmul(weights,features.t()))\n",
    "\n",
    "# Calculating output\n",
    "output = torch.matmul(weights, features.t()) + bias\n",
    "\n",
    "y=activation((output))\n",
    "print(y)\n",
    "\n",
    "y1 = activation(torch.mm(weights, features.t()) + bias) \n",
    "# mm better than matmul, because mm gives error if something is not right\n",
    "# but matmul doesn't.\n",
    "print(y1)\n",
    "\n",
    "\n",
    "\n",
    "# reshaping tensors\n",
    "print(\"\\n\\n\",features)\n",
    "features = features.reshape(5,1)\n",
    "print(features)\n",
    "features = features.resize_(1,5)\n",
    "print(features)\n",
    "features = features.view(5,1) # best of lot\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6124, 0.9520]])\n",
      "tensor([[0.2657]])\n"
     ]
    }
   ],
   "source": [
    "# Neural network with hidden layer\n",
    "torch.manual_seed(78)\n",
    "\n",
    "features=torch.randn((1,3))\n",
    "# print(features)\n",
    "\n",
    "n_input = features.shape[1]   # no of input units\n",
    "# print(n_input)\n",
    "\n",
    "n_hidden = 2   # no of elements in hidden layer(only 1 hidden layer)\n",
    "n_output = 1   # no of elements in putput \n",
    "\n",
    "# weights for inputs to hidden layer\n",
    "w1 = torch.randn(n_input, n_hidden)   # 3,2\n",
    "# print(w1)\n",
    "\n",
    "# weights for hidden layer to output layers\n",
    "w2 = torch.randn(n_hidden, n_output)  # 2,1\n",
    "# print(w2)\n",
    "\n",
    "# and bias terms for hidden and output layers\n",
    "b1 = torch.randn(1, n_hidden)\n",
    "# print(b1)\n",
    "b2 = torch.randn(1, n_output)\n",
    "# print(b2)\n",
    "\n",
    "# calculating hidden layer nodes\n",
    "h = activation(torch.mm( features,w1) + b1)\n",
    "# print(torch.mm( features,w1) , b1)\n",
    "print(h)\n",
    "\n",
    "y = activation(torch.mm(h,w2) +b2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02176012 0.42681666 0.44484458]\n",
      " [0.30227733 0.84809405 0.29347909]\n",
      " [0.98662679 0.70745863 0.07498191]\n",
      " [0.52711625 0.35272845 0.79364727]]\n",
      "tensor([[0.0218, 0.4268, 0.4448],\n",
      "        [0.3023, 0.8481, 0.2935],\n",
      "        [0.9866, 0.7075, 0.0750],\n",
      "        [0.5271, 0.3527, 0.7936]], dtype=torch.float64)\n",
      "[[0.02176012 0.42681666 0.44484458]\n",
      " [0.30227733 0.84809405 0.29347909]\n",
      " [0.98662679 0.70745863 0.07498191]\n",
      " [0.52711625 0.35272845 0.79364727]]\n",
      "tensor([[0.0435, 0.8536, 0.8897],\n",
      "        [0.6046, 1.6962, 0.5870],\n",
      "        [1.9733, 1.4149, 0.1500],\n",
      "        [1.0542, 0.7055, 1.5873]], dtype=torch.float64)\n",
      "[[0.04352024 0.85363332 0.88968915]\n",
      " [0.60455466 1.69618811 0.58695817]\n",
      " [1.97325358 1.41491725 0.14996382]\n",
      " [1.05423251 0.7054569  1.58729455]]\n"
     ]
    }
   ],
   "source": [
    "# Numpy and torch tensor , array conversion\n",
    "import numpy as np\n",
    "a = np.random.rand(4,3)\n",
    "print(a)\n",
    "\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "\n",
    "print(b.numpy())\n",
    "\n",
    "# the memory is shared between numpy array and torch tensor, if we change\n",
    "# values of one inplace then other's value will also change\n",
    "print(b.mul_(2)) # .mul_ implice inplace , .mul is nor inplace\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building large neural network on mnist dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5,), std=(0.5,))\n",
      ")\n",
      "<class 'torchvision.datasets.mnist.MNIST'> Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: MNIST_data/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5,), std=(0.5,))\n",
      "           )\n",
      "\n",
      "\n",
      "\n",
      " <class 'torch.utils.data.dataloader.DataLoader'> <torch.utils.data.dataloader.DataLoader object at 0x7f59621610d0>\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print('Started')\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor(), \n",
    "#                                transforms.Normalize((0.5,0.5,0.5), \n",
    "#                                                    (0.5,0.5,0.5)),])\n",
    "\n",
    "# Because the data set is grayscale\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                               transforms.Normalize((0.5,), \n",
    "                                                   (0.5,)),])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(transform)\n",
    "trainset = datasets.MNIST( 'MNIST_data/', download=True, train=True, transform=transform)\n",
    "print(type(trainset), trainset)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "print(\"\\n\\n\\n\",type(trainloader), trainloader)\n",
    "\n",
    "# The batch size is no of images we get in one iteration from data loader\n",
    "# and pass through our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7f5990108350>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "print(dataiter)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f596204e050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze())\n",
    "# plt.imshow(images[15].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256]) torch.Size([64, 10])\n",
      "tensor([ -1.1026,  23.4447,   2.6175, -17.2043,  20.8516,  -7.4765,   2.3006,\n",
      "         -0.5625,   6.4287, -16.1730])\n"
     ]
    }
   ],
   "source": [
    "images = images.view(64,784)\n",
    "# Another method to change size of inputs vector\n",
    "# # print(images.shape[0])\n",
    "# inputs = images.view(images.shape[0], -1)\n",
    "# # print(inputs.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(images.shape)\n",
    "# We want to build, a hidden layer with 256 units, output layer with 10 units and input layer with 784 units\n",
    "\n",
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "n_input = 784\n",
    "n_hidden = 256\n",
    "n_output = 10\n",
    "w1 = torch.randn((n_input, n_hidden)) \n",
    "# print(w1.shape)\n",
    "w2 = torch.randn((n_hidden, n_output))\n",
    "\n",
    "# b1 = torch.randn((1,n_hidden)) # wrong way\n",
    "b1 = torch.randn(256) # correct way\n",
    "\n",
    "# b2 = torch.randn((1,n_output))\n",
    "b2 = torch.randn(n_output)\n",
    "\n",
    "h = activation(torch.mm(images, w1) +b1)\n",
    "# print(torch.mm(images, w1),b1,h)\n",
    "y = torch.mm(h, w2) +b2\n",
    "print(h.shape,y.shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " torch.Size([64, 10])\n",
      "tensor([2.0321e-11, 9.3041e-01, 8.3862e-10, 2.0656e-18, 6.9586e-02, 3.4656e-14,\n",
      "        6.1084e-10, 3.4875e-11, 3.7910e-08, 5.7934e-18])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.sum(torch.exp(x), dim=1).view(-1,1)\n",
    "\n",
    "# print(torch.exp(y).shape) # 64,10\n",
    "# print(torch.sum(torch.exp(y))) # 1,1 it sums of ull 64,10 tensor\n",
    "# print(torch.sum(torch.exp(y), dim=0).shape) # 10 it sums column wise\n",
    "# print(torch.sum(torch.exp(y), dim=1).shape) # 64 it sums row wise\n",
    "# print(torch.sum(torch.exp(y), dim=1).view(-1,1).shape) #64,1\n",
    "# print(torch.sum(torch.exp(y), dim=1)) #1 row, 64 columns\n",
    "# print(torch.sum(torch.exp(y), dim=1).view(-1,1)) # 64 rows with 1 cloumn\n",
    "\n",
    "probabilities = softmax(y)\n",
    "print(\"\\n\\n\",probabilities.shape)\n",
    "print(probabilities[0])\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large neural network with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer, to perform linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # taking inputs,multiply by weights, add bias is a linear\n",
    "        # transformation\n",
    "        # Output layer linear transformation\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "        # sigmoid and softmax function\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Passing input tensor through our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using torch.nn.functional module to do it more cleanly\n",
    "import torch.nn.functional as F\n",
    "class Network1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer, to perform linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer linear transformation\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid function\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network1(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Network1()\n",
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Neural net with ReLu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer, to perform linear transformation\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        self.hidden2 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Output layer linear transformation\n",
    "        self.output = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid function\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "model = Network()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training neural network, and calculating loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n",
      "torch.Size([64, 10])\n",
      "tensor([-0.2376,  0.0800, -0.1280,  0.1755,  0.1515,  0.0447, -0.0729,  0.1273,\n",
      "        -0.1324, -0.0207], grad_fn=<SelectBackward>)\n",
      "tensor(2.3066, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer, to perform linear transformation\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        self.hidden2 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Output layer linear transformation\n",
    "        self.output = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid function\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x\n",
    "model = Network()\n",
    "\n",
    "# loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# calculating logits\n",
    "# Logits is a function which operates on the unscaled output of earlier\n",
    "# layers and on a linear scale to understand the linear units. In \n",
    "# Mathematics, Logits is a function that maps probabilities ( [0, 1] )\n",
    "# to R ( (-inf, inf) ) .\n",
    "print(images.shape)\n",
    "logits = model(images)\n",
    "print(logits.shape)\n",
    "print(logits[0])\n",
    "loss = criterion(logits, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.1262, -2.5900, -2.3197, -2.4384, -2.1363, -2.0870, -2.3810, -2.3205,\n",
      "        -2.3346, -2.4035], grad_fn=<SelectBackward>)\n",
      "tensor(2.3256, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# using log-softmax as output activatio function and negative log likelihood\n",
    "# loss as loss criterion\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim=1) #log softmax as output\n",
    "                     )\n",
    "# model\n",
    "\n",
    "criterion = nn.NLLLoss() # calculating loss as negative log liklihood\n",
    "# loss\n",
    "\n",
    "log_probability = model(images)\n",
    "print(log_probability[0])\n",
    "loss = criterion(log_probability, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6238, -1.2271],\n",
      "        [-0.1789, -1.3841]], requires_grad=True)\n",
      "tensor([[0.3892, 1.5057],\n",
      "        [0.0320, 1.9158]], grad_fn=<PowBackward0>)\n",
      "<PowBackward0 object at 0x7f59625c8550>\n",
      "tensor(0.9607, grad_fn=<MeanBackward0>)\n",
      "None None\n",
      "tensor([[-0.3119, -0.6135],\n",
      "        [-0.0895, -0.6921]])\n",
      "tensor([[-0.3119, -0.6135],\n",
      "        [-0.0895, -0.6921]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Performing back propagation using autograd. Autograd works by keeping \n",
    "# track of operations performed on tensors, then going backwards through\n",
    "# those operations, calculating gradients along the way. But we have to\n",
    "# set requires_grad parameter to True of tensor\n",
    "# torch.no_grad() to revert\n",
    "# torch.set_grad_enabled(True | False)\n",
    "torch.manual_seed(78)\n",
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x**2\n",
    "print(y)\n",
    "\n",
    "# To know ehich function generated variable y, pow function\n",
    "print(y.grad_fn)\n",
    "\n",
    "z = y.mean()\n",
    "print(z)\n",
    "\n",
    "print(x.grad,y.grad)\n",
    "# currently grad og x,y are empty\n",
    "# to calculate gradients we have to run backward on z, this will calculate\n",
    "# gradient of z wrt x\n",
    "\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass:\n",
      " None\n",
      " After backward pass:\n",
      " tensor([[ 0.0029,  0.0029,  0.0029,  ...,  0.0029,  0.0029,  0.0029],\n",
      "        [-0.0011, -0.0011, -0.0011,  ..., -0.0011, -0.0011, -0.0011],\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
      "        ...,\n",
      "        [-0.0021, -0.0021, -0.0021,  ..., -0.0021, -0.0021, -0.0021],\n",
      "        [ 0.0001,  0.0001,  0.0001,  ...,  0.0001,  0.0001,  0.0001],\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005]])\n"
     ]
    }
   ],
   "source": [
    "# Loss and autograd\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "log_prob = model(images)\n",
    "loss = criterion(log_prob, labels)\n",
    "\n",
    "print('Before backward pass:\\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(' After backward pass:\\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0274,  0.0156,  0.0121,  ..., -0.0352,  0.0251,  0.0153],\n",
      "        [-0.0166,  0.0113, -0.0022,  ..., -0.0041, -0.0097, -0.0180],\n",
      "        [-0.0202, -0.0013,  0.0287,  ...,  0.0140,  0.0125, -0.0102],\n",
      "        ...,\n",
      "        [-0.0299,  0.0229, -0.0042,  ..., -0.0220,  0.0047, -0.0133],\n",
      "        [ 0.0085, -0.0207,  0.0202,  ...,  0.0053,  0.0309,  0.0026],\n",
      "        [-0.0190,  0.0194, -0.0260,  ...,  0.0096,  0.0197,  0.0052]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[ 0.0028,  0.0028,  0.0028,  ...,  0.0028,  0.0028,  0.0028],\n",
      "        [-0.0008, -0.0008, -0.0008,  ..., -0.0008, -0.0008, -0.0008],\n",
      "        [ 0.0029,  0.0029,  0.0029,  ...,  0.0029,  0.0029,  0.0029],\n",
      "        ...,\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        [ 0.0006,  0.0006,  0.0006,  ...,  0.0006,  0.0006,  0.0006],\n",
      "        [ 0.0014,  0.0014,  0.0014,  ...,  0.0014,  0.0014,  0.0014]])\n"
     ]
    }
   ],
   "source": [
    "# Upgrading weights using optimizers, like optim.SGD (stochastic gradient\n",
    "# descent)\n",
    "from torch import optim\n",
    "\n",
    "# optimizers require parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# The general process of training\n",
    "\"\"\"1) Make a forward pass through network.\n",
    "2) Use network output to calculate loss\n",
    "3) Perform backward pass through network with loss.backward() to calculate\n",
    "gradients\n",
    "4) Take a step with optimizer to update weights.\"\"\"\n",
    "\n",
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear gradients, it is required because gradients are accumulated,\n",
    "# it is called before every training pass\n",
    "optimizer.zero_grad()\n",
    "\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights - Parameter containing:\n",
      "tensor([[-0.0277,  0.0154,  0.0118,  ..., -0.0355,  0.0248,  0.0150],\n",
      "        [-0.0166,  0.0114, -0.0021,  ..., -0.0040, -0.0096, -0.0180],\n",
      "        [-0.0205, -0.0016,  0.0284,  ...,  0.0137,  0.0122, -0.0105],\n",
      "        ...,\n",
      "        [-0.0299,  0.0229, -0.0041,  ..., -0.0220,  0.0047, -0.0132],\n",
      "        [ 0.0085, -0.0208,  0.0201,  ...,  0.0052,  0.0308,  0.0026],\n",
      "        [-0.0192,  0.0193, -0.0262,  ...,  0.0095,  0.0195,  0.0051]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take update ste to update weights\n",
    "optimizer.step()\n",
    "print('Updated weights -', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the whole MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.8967233725956507\n",
      "Training loss: 0.8649482572002452\n",
      "Training loss: 0.5397959950445558\n",
      "Training loss: 0.4401901340179606\n",
      "Training loss: 0.3918095511445867\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # print(images.shape[0]) # 64\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        # print(images.shape) # [64, 784]\n",
    "        \n",
    "        optimizer.zero_grad() # it is very important step\n",
    "\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Training loss:\", running_loss/len(trainloader))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "img = images[0].view(1, 784)\n",
    "\n",
    "# Turning off gradients to spped up this part\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "    \n",
    "# output of this network are logits, need to take softmax for probabilities\n",
    "prob = F.softmax(logits, dim=1)\n",
    "view_classify(img.view(1, 28, 28), prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
